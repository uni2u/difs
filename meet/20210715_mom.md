
## Minutes Of Meeting
- 안건: DIFS 테스트 베드 구성 및 이슈 협의
  - 아래 명시함 (기능개선, 성능개선, HashChain ver2)
    - 우선순위로 작성된 것은 아님
    - 회의 진행을 위하여 비교적 간단한 내용을 먼저 작성함
- 참석자
  - 데이터중심네트워크연구실: 신용윤, 박세형
  - 구름네트웍스: 김성호, 박태웅
- 일시: 2021.07.15. (목) 11시 00분 ~ 16시 30분
  - COVID19 에 대한 원내 지침으로 2주간 연기
  - 예정: 2021.07.29. (목) 11시 00분 ~ 16시 30분
  - COVID19 에 대한 비수도권 거리두기 3단계 격상: 원내 지침으로 2주간 연기
  - 온라인: 2021.07.29. (목) 14:00
- 장소: 온라인 (Skype); 7-286

---

## [기능개선] - 대부분 완료 stage
- 기본 기능 확인 완료
- 발생가능한 모든 CASE 에 대응하는 것은 현 단계에서 필요하지 않은 것으로 판단함
- 성능개선 (8월) 을 우선하며 성능개선 이후 여유가 되는 경우 적용함을 원칙으로 함 
- 단, 주요 이슈인 경우 예외적으로 적용할 수 있도록 함
  - INC 연동
  - 모니터링 (협의 필요)

### 1. (95%-반복테스트) 기능개선-KeyValue Store (mongodb)
#### 1-1. 상태 (기능개선-KeyValue Store)
- mongodb 기반의 저장소 구축
  - db: difs
  - collection: data/manifest
#### 1-2. 이슈 (기능개선-KeyValue Store)
- 현재까지 기본 기능에 대한 이슈 없음
- mongodb 자체가 메모리 영향을 받기 때문에 주의깊게 테스트 중
- mongodb 자체의 성능 향상 포인트를 찾아 적용해볼 수 있음
  - insertMany 적용 등
  - DIFS 가 _Interest_ 를 전송하여 data segment 를 받으면
    - mongo 에 저장 후 validation ? / validation 후 mongo 에 저장?

---

### 2. (90%-연동테스트) 기능개선-모니터링
#### 2-1. 상태 (기능개선-모니터링)
- 클러스터링 정보
  - `build/bin/ndngetKeyInfo /<common-name>`
    - keyspace file 을 통한 클러스터링 정보 확인
  - dashboard 파트와 연동 테스트 예정 (8월)
    - `ndn://<common-name>/ringinfo` 
- 노드 정보
  - `build/bin/ndngetInfo /<node-name>`
    - 노드 리소스 (disk, mem usage) 정보 확인
    - 노드 데이터 (manifest, segment) 정보 확인
  - dashboard 파트와 연동 테스트 예정 (8월)
    - `ndn://<node-name>/nodeinfo` 
#### 2-2. 이슈 (기능개선-모니터링) - dashboard 담당자와 협의 완료
- 노드 정보에서 manifest 및 segment 는 매우 많아질 수 있음
- 이 경우 노드 정보 요청 _Interest_ 에 대한 응답이 8,800K 를 넘어설 수 있음
  - 방안1) dashboard 측에서 노드 정보 데이터를 sequence 에 따라 처리
    - dashboard 에 스크롤이 많이 발생할 수 있음
  - 방안2) summary 를 사용한 요약 정보로 응답
    - 저장중인 데이터의 ndn-name 으로 segments 를 대신하거나
    - segments 를 모두 표기하지 않고 최초 segment 외 x 개로 표기 
  - 방안3) data 의 경우 첫번째 sequence 만 표기
    - manifest 는 리스트가 길어져도 무관
    - data 는 segment 가 모두 표기되기 때문에 하나의 데이터라도 수많은 리스트가 발생할 수 있음
    - data 는 무조건 segment 의 첫번째만 표기함
    - 서로 다른 데이터에 대한 segment 를 구분할 수 있는지 확인 필요
- 방안1) 을 기본으로 모니터링 담당자와 의견 조율
  - dashboard 담당(모두텍)에게 메일로 의견 조율함
  - 방안1에 대한 모두텍 담당자의 수용 메일 답변 받음 (2021.07.19. 08:55)
  - DIFS 에서 모니터링 관련 데이터 생성시 segment num 을 추가하여야 함
    - 첫번째 데이터를 전송하면서 END_BLOCK_ID 를 명시하여 dashboard 가 접근할 수 있도록 

---

### 3. (95%-반복테스트) 기능개선-동적노드구성
#### 3-1. 상태 (기능개선-동적노드구성)
- 오퍼레이터 (저장소, 네트워크 관리자) 가 노드를 추가하는 것을 가정함
  - 오퍼레이터는 관리하는 저장소 및 네트워크의 name 등을 모두 알고 있음
- db type 을 config 에 명시하여 동작
  - 추가 노드에 manager, from, to 노드 name 명시
- 현재 fs, mongodb 타입 구성 가능
  - 혼합 구성 가능
- keyspace 구성 및 업데이트 확인
  - 노드가 추가된 경우 keyspace 업데이트
- manifestList 생성 및 manifest 이동 확인
  - 노드 추가 및 삭제에 따른 manifest 이동
#### 3-2. 이슈 (기능개선-동적노드구성)
- 노드가 2개만 남은 경우 (manager, node) 일반 노드 delete
  - version check, fetch, coordination 과정 후 manifestList 요청
  - manager 노드가 자신에게 version check, fetch, coordination 을 하지 않기 때문에 문제 발생
  - manager 노드가 coordination 과정을 자신에게 보내고 manifestList 를 가져올 수 있도록 함
  - 성능 개선 (8월) 이후 시간이 된다면 적용
    - 현 상태를 완료로 보아도 무방함

---

### 4. (90%-INC 연동 테스트 필요) 기능개선-INC 연동
#### 4-1. 상태 (기능개선-INC 연동)
- INC container 를 미리 생성한다는 의미에서 producer 가 INC 로 생성된 container 인 경우
  - DIFS 는 container 로 데이터를 요청하여야 하는데
  - container 가 어떤 name 으로 생성되었는지 알 수 없기 때문에
  - container 가 생성되면 container 에서 full-prefix 를 DIFS 로 전달할 수 있어야 함
    - REPO_PARAMETER_NODE_PREFIX 정의
    - container 는 완전하게 생성된 후 full-prefix 를 ForwardingHint 에 실어 ndnputfile 시 DIFS 로 전송
    - 기본적으로 ForwardingHint 와 동일 동작
#### 4-2. 이슈 (기능개선-INC 연동)
- INC 파트에서 해당 기능이 검증되어야 하며 이때 DIFS lib 도 함께 검증할 수 있도록 함

---

### 5. (90%-반복테스트) 기능개선-HashChain 1차
#### 5-1. 상태 (기능개선-HashChain 1차)
- metaInfo 의 AppMetaInfo 를 사용하고자 하였으나 NFD 까지 영향이 있는 것으로 확인하여 더이상 진행하지 않음
- content 필드의 앞부분 32bit 를 사용한 next-hash 구성
- ndn-cxx 0.7.1 에 hc-key-chain 및 hc-segment-fetcher 클래스 생성
  - 블록 구성은 client 에서 구성함
    - 다양한 기법을 활용하여 성능적 우위를 지닐 수 있음
    - 블록 구성을 라이브러리에서 대신하는 경우 여러 기법을 활용한 블록 구성에 제한이 될 수 있음
  - 본 difs-cxx 를 사용하는 경우 무조건 HashChain 으로 동작하며 config 의 validator 를 사용하지 않음
    - validator 는 hc-segment-fetcher 를 활용함
    - 데이터를 저장함에 있어 검증을 거친 후 저장이 완료됨
      - consumer 는 별도로 검증 작업을 진행하여야 함
#### 5-2. 이슈 (기능개선-HashChain 1차)
- 데이터가 순서대로 전송되지 않는 경우
  - 현재 TCP 모드에서 순서를 보장해 주는 것으로 가정하고 있음
  - 현재 다른 파트의 예에서 순서 보장이 되는 것으로 확인함
  - 방안1) 현재 DIFS 는 순서대로 데이터가 오지 않는 경우 해당 validate 를 skip 하는 구성이 적용됨
    - 순서대로 들어온 경우 일반 validate 진행
    - 순서대로 들어오지 않는 경우 skip validate 진행
    - 해당 함수 이름이 randAfterValidationSuccess 로 되어 있음
  - 방안2) timeout 적용
    - 데이터가 순서대로 오지 않으면 일정시간 대기후 timeout 발생
    - 일정시간 대기로 인하여 성능이 저하될 수 있음
  - 성능 개선 (8월) 이후 시간이 된다면 적용
    - 현 상태를 완료된 것으로 보아도 무방함
    - 단, 순서대로 전송되지 않는 경우가 발생할 경우 방안1) 을 따르도록 되어있음 

---

### 6. 1차 KOREN 연동
#### 6-1. 상태 (1차 KOREN 연동)
- 8월 2주차부터 KOREN 망 연동 테스트 예정
- 연동 모듈: mwNFD, INC, dashboard
  - mwNFD: 연동에 문제가 없다고 이야기 하지만 실제 연동에는 문제가 발생할 수 있음
    - https://github.com/etri/mw-nfd
    - 상기 github 에 포함된 ndn-cxx 를 hash-chain 클래스가 포함되도록 한 뒤 rebuild 하여야 함
    - 라우터 이름: `/<network>/<site>/%C1.Router/<router-name>`
      - network: dcn
      - site: daejeon, seoul, pangyo, busan, gwangju
      - ex) /dcn/daejeon/%C1.Router/daejeon-R1
    - 각 특수 문자가 포함된 name 처리 확인 필요
  - INC: INC 파트에서 DIFS 와 연동 관련 로컬 테스트를 진행하지 않는한 DIFS 에서는 로컬 연동 테스트를 할 수 없음
  - dashboard: 관련 _Interest_ 에 대한 데이터 확인 및 dashboard 담당자와 의견 조율 
    - _Interest_ 및 json 형식의 string 예제 전달
    - 2021.07.13. 15:53 메일 발송 완료 (아래 메일 원문)
    - 2021.07.16. 11:36 방안1에 대한 내용 메일 발송 완료 (아래 메일 원문)
    - 2021.07.19. 08:55 방안1에 대한 모두텍 담당자 수용 답장 받음 (아래 메일 원문)
```
받는사람: sormfla@modutech.co.kr, geunii@modutech.co.kr
참조: sungho@gurum.cc, taewoong@gurum.cc

안녕하세요?

ETRI 신용윤 입니다.

KOREN 모니터링 저장소(DIFS) 파트 관련하여 다음과 같이 `Interest / 데이터 포멧` 을 알립니다.

현재 4개의 노드가 클러스터를 구성하고 있으며 <common-name> 은 `/difs` 로 정의되어 있습니다.

- DIFS :: main page
  - Interest: `ndn://<common-name>/ringinfo`
  - data: `{"keyspaces":[{"node":"\/seoul\/difs","start":"0x00","end":"0x7f"},{"node":"\/busan\/difs","start":"0x80","end":"0xbf"},{"node":"\/daejeon-01\/difs","start":"0xc0","end":"0xdf"},{"node":"\/daegu-01\/difs","start":"0xe0","end":"0xff"}]}`
    - data 는 json 형식의 string 으로 제공되며 ‘\’ 이 포함되어 있으니 이점 유의 부탁드립니다.

위 내용으로 4개의 노드는 각각 `/seoul/difs`,  `/busan/difs`, `/daejeon-01/difs`, `/daegu-01/difs` 임을 확인할 수 있습니다.
또한 각 노드의 KEYSPACE 정보가 포함되어 있음을 확인할 수 있습니다.

이 노드 중 /seoul/difs 와 /busan/difs 에 각각 데이터를 저장하고 각 노드의 정보를 살펴보면 다음과 같습니다.

- DIFS :: after selection DIFS node
  - Interest: `ndn://<node-name>/nodeinfo`
  - data:
    - /seoul/difs 의 경우: `{"name":"\/seoul\/difs\/info","disk":{"disk":{"size":"460440616","usage":"419559936"}},"memory":{"memory":{"size":"32784340","usage":"19956440"}},"datas":[{"data":"\/test\/%00%00"}],"manifests":[{"key":"7793e419e24287ca07c18103f02e7994978d5130"}]}`
    - /busan/difs 의 경우: `{"name":"\/busan\/difs\/info","disk":{"disk":{"size":"460440616","usage":"419624936"}},"memory":{"memory":{"size":"32784340","usage":"21045444"}},"datas":[{"data":"\/test02\/%00%00"}],"manifests":”"}`
    - /daejeon-01/difs 의 경우: `{"name":"\/daejeon-01\/difs\/info","disk":{"disk":{"size":"1152665260","usage":"1076758796"}},"memory":{"memory":{"size":"32784404","usage":"21382544"}},"datas":"","manifests":”"}`
    - /daegu-01/difs 의 경우: `{"name":"\/daegu-01\/difs\/info","disk":{"disk":{"size":"460440616","usage":"419493160"}},"memory":{"memory":{"size":"32784340","usage":"20423308"}},"datas":"","manifests":[{"key":"f133a4599372cf531bcdbfeb1116b9afe8d09b4f"}]}`

문의 사항이 있으시면 제게 문의해주시기 바랍니다.

이상입니다.

ETRI 신용윤 드림

---

받는사람: sormfla@modutech.co.kr, geunii@modutech.co.kr
참조: sungho@gurum.cc, taewoong@gurum.cc

안녕하세요?

한국전자통신연구원 신용윤 입니다.

일전에 저장소 모니터링 관련한 메일을 보내드렸습니다. (하단 메일 원문)

다름이 아니라 한가지 알려드릴 사항이 있어 메일을 보냅니다.

모니터링 기능 중 각 노드의 cpu/mem/data/manifest 등의 정보를 보는 페이지가 있습니다.

- 정보 중에 data/manifest 의 경우 파일이 규정 크기를 넘어갈 수 있습니다.
  - NDN 에서 패킷의 크기는 8,800 byte 입니다.
  - 즉, 데이터 조각은 8,800byte 로 쪼개져서 저장이 됩니다.
  - 이러한 경우 저장된 데이터가 64M 라면 약 7,200 개의 조각이 생성됩니다.
  - 또한, manifest 도 시간이 지나면서 점점 늘어나게 됩니다.

- dashboard 에서 저장소로 `ndn://<node-name>/nodeinfo` 을 전송하는 경우
  - 데이터 조각의 name 을 모두 담아서 응답하기 때문에 8,800 byte 를 넘어갈 수 있습니다.
  - 이 경우 DIFS 는 모니터링 응답 패킷을 나누고 segment 번호를 붙이게 됩니다.
    - 64M 데이터에 대한 조각은 약 7,200 개가 생성되며 각 조각마다 순차적으로 segment 번호가 생성됩니다.
  - 위 Interest 의 응답으로 첫번째 조각이 전송되며 패킷 정보에 마지막 조각 번호가 포함됩니다.
    - 2번 조각을 얻기 위하여 dashboard 에서 다음과 같이 Interest 를 발생하여야 합니다.
      - `ndn://<node-name>/nodeinfo/<segment number>`
      - <segment number> 는 순차적으로 증가합니다.
  - dashboard 에서 마지막 조각을 획득하고 조각을 합체하면 데이터가 완성됩니다.
  - dashboard 파트에서 화면을 구성할 때 적절히 표현될 수 있도록 반영하셔야 합니다.
    - 	64M 데이터에 대한 리스트 7,200 개를 받았다면 ‘xxxx 외 7,150’ 등으로 표기

이상입니다.

신용윤 드림

=== [답장확인]

받는사람: uni2u@etri.re.kr, sungho@gurum.cc, taewoong@gurum.cc
참조: sormfla@modutech.co.kr

안녕하세요.
(주)모두텍 신동근입니다.

전달 주신대로 세그먼트 번호를 이용해 interest를 보내고
data를 merge할 수 있도록 구현하겠습니다.

감사합니다.
신동근 드림

```

#### 6-2. 이슈 (1차 KOREN 연동)
- 8월 연동 일정에 따라 이슈 대처 예정

---

## [성능개선] - 중점 개발 stage
- 8월말 까지 목표로 성능 개선에 중점
- 특히, HashChain 의 경우 여러 방안을 고민할 필요가 있음

### 1. (95%-반복테스트) 성능개선-ForwardingHint
- operator 가 insert 요청시 적용한 ndn-name 으로 저장
  - 기존: node-name/ndn-name
  - 변경: ndn-name 
- 저장 노드의 라우팅 테이블 '/' 로 고정
  - 기존: ndn-name 마다 라우팅 테이블 생성
  - 변경: / 적용으로 모든 트래픽이 root 를 향할 수 있도록 함
- segmentfetcher 이슈
  - segmentfetcher 요청이 모두 '/' 로 전달되어 read 함수를 호출하는 이유로 mongodb insert 속도 저하 발생
    - 기존 '/data-name' 으로 router 에 등록
    - 또는 다른 방안

### 2. (50%-성능최적화) 성능개선-코드 최적화
- 중복 코드 정리 및 메커니즘 정리
- mongoDB 최적화
  - bulk.insert / insertMany 등
    - 관련 이슈는 difs github Issues 를 통하여 토의
- appMetaInfo 기반 next-hash 구현
  - `MetaInfo 디코딩 후 setType, setFreshnessPeriod, setFinalBlock 을 AppMetaInfo보다 먼저 호출하는 경우 모든 앱 정의 블록 손실`
  - 위 내용은 https://github.com/named-data/ndn-cxx/blob/master/ndn-cxx/meta-info.hpp 코드에서 확인
  - 해당 부분을 적용하여 appMetaInfo 에 next-hash 적용함
  - ndngetfile 에서 TIMEOUT 발생
    - 표면상 large data 의 경우 발생
    - forwardinghint 적용시 라우팅 등록 '/' 때문일 수 있음
    - ndngetfile TIMEOUT 발생 (아래 로그, https://github.com/uni2u/difs-cxx/issues/8)

```
수정 버전을 기반으로 간단한 테스트 시 ndngetfile TIMEOUT 발생 가능성이 있음

- 반드시 발생하는 것이 아니기에 확정지을 수 없음
  - 또한, appMetaInfo 를 사용하면 패킷 drop 이 있을 수 있다고 하였는데
  - packet drop 으로 인하여 발생한 것인지 확실하지 않음
- 기존 content 필드에 next-hash 를 넣은 버전은 더미 데이터의 값(알 수 없는 부호)이 프린트 되기에 확인 가능
- appMetaInfo 활용 버전의 경우 이 값이 프린트 되지는 않음
  - 반드시 프린트 할 필요는 없지만 첫번째 패킷만 수신한 것 처럼 프린트 됨
    - ndngetfile 시 file size 에 따른 대기시간으로 볼 때 패킷 수신은 된것 처럼 느껴짐
- 단, appMetaInfo 적용 버전에서 TIMEOUT 이라는 메시지가 발생하는 경우가 있음 (NFD 로그에서 발생하는 것이 아님)
  - 1G 사이즈에서는 TIMEOUT 메시지가 프린트 됨
- push 하기 전 64M, 1G 등 더미 파일에 대한 ndnputfile/ndngetfile 테스트를 진행할 필요 있음

[64M]
root@playground03:/home/uni2u/difs-mongo# build/bin/ndnputfile /difs /64m /tmp/64m.txt
root@playground03:/home/uni2u/difs-mongo# build/bin/ndngetfile /difs /64m
/64m/%00%00

[128M]
root@playground03:/home/uni2u/difs-mongo# build/bin/ndnputfile /difs /128m /tmp/128m.txt
root@playground03:/home/uni2u/difs-mongo# build/bin/ndngetfile /difs /128m
/128m/%00%00

[256M]
root@playground03:/home/uni2u/difs-mongo# build/bin/ndnputfile /difs /256m /tmp/256m.txt
root@playground03:/home/uni2u/difs-mongo# build/bin/ndngetfile /difs /256m
/256m/%00%00

[512M]
root@playground03:/home/uni2u/difs-mongo# build/bin/ndnputfile /difs /512m /tmp/512m.txt
root@playground03:/home/uni2u/difs-mongo# build/bin/ndngetfile /difs /512m
/512m/%00%00

[1G]
root@playground03:/home/uni2u/difs-mongo# build/bin/ndnputfile /difs /1g /tmp/1g.txt
root@playground03:/home/uni2u/difs-mongo# build/bin/ndngetfile /difs /1g
/1g/%00%00
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
Timeout
root@playground03:/home/uni2u/difs-mongo#
```

- mongodb insert 관련
  - `ndnputfile` 로 인하여 호출된 mongodb 관련 insert 처리
    - 기존: replace_one 함수
      - 처리에 시간이 많이 소요됨
    - 수정: insert_many 함수
      - 약 300 개의 chunk 를 쌓은 후 insert 처리
  - collection 접근 횟수에 따른 시간
    - 1G) insert_one: 12만번 collection 접근
    - 1G) insert_many: 4,000번 collection 접근
      - file system type 성능과 비슷

### 3. (60%-메커니즘) 성능개선-HashChain 1차
- 데이터 패킷 구성 지연
  - 현재 Backward Chain 기반의 HashChain 구성으로 완전체 패킷을 뒤에서 부터 읽고 hash 를 만들어 next-hash 를 구성
  - next-hash 가 구성된 후 다시 1번 패킷부터 블록 생성
  - 만들어진 블록에 Signature 를 추가하여 전송
- 방안1) 코드 안정화 및 성능이 좋은 알고리즘, 테크닉 추가
  - 중복 코드 제거 및 성능 향상을 위한 코드 추가
  - 성능 향상 테크닉 추가
    - mongodb 의 장점을 살릴 수 있는 방법
    - hash 를 의미있게 만들어 보는 방법
      - 블록 갯수, node-name, ndn-name 등을 활용한 규칙성 있는 hash 생성
        - hash 를 미리 알 수 있기 때문에 바로 블록을 구성할 수 있을 것으로 예상
        - 예) aa 11 yy bb 22 zz
          - aa bb : ndn-name 을 hash 한 값의 일부 적용
          - 11 22 : 블록 갯수를 hash 한 값의 일부 적용
          - yy zz : sequence number 를 hash 한 값의 일부 적용
- 방안2) Forward Chain 기반의 HashChain 구성
  - 각 패킷이 next-hash 가 아닌 previous-hash 를 가지게 됨
  - DigestSha256 값에 previous-hash 를 넣어 패킷 구성
  - 저장소는 받은 데이터를 검증
    - 받은 패킷의 DigestSha256 으로 이전 패킷을 검증할 수 있음
    - 하지만 완전한 검증이 아님 (ECDSA 또는 RSA 를 통한 검증이 되지 않았기 때문)
  - 저장소는 데이터를 모두 받은 뒤 마지막 패킷의 SignatureType 에 따라 ECDSA 검증
    - 이를 통하여 완전 검증이 완료되며 저장 완료
  - 단, 이것을 다시 Backward Chain 으로 재구성을 할 필요가 있음
    - 소비자는 다운로드 중인 현재 패킷에 이상이 있으면 즉시 데이터 요청을 하지 않아야 하기 때문
      - Backward Chain 의 경우 현재 패킷에 next-hash 가 DigestSha256 으로 구성
      - 소비자 입장에서 현재 다운로드 된 패킷을 검증할 때 이미 다운로드 된 이전 패킷의 next-hash 로 즉시 검증
- 방안3) DIFS 데이터 저장 완료 후 검증
  - DIFS 의 저장완료는 데이터 검증까지 끝난 완전하게 저장된 시점을 의미함
  - 데이터 저장소 입장으로 실시간 데이터 보다 persistent data 저장에 의미를 둘 수 있음
  - persistent data 에 의미를 둔다면 per segment 검증보다 데이터 전체에 대한 검증이 의미있음
    - 이 경우 hash chain 의 의미는 퇴색
    - 우선 데이터 저장 이후 검증하는 메커니즘을 사용할 수 있음

---

### 4. 2차 KOREN 연동
#### 4-1. 상태 (2차 KOREN 연동)
- 10월 KOREN 망 연동 테스트 예정
  - 8월 1차 연동으로 인하여 테스트 문제는 해소될 것으로 예상
  - 10월에는 성능 관련 업데이트 사항이 주된 목표
#### 4-2. 이슈 (2차 KOREN 연동)
- 10월 연동 일정에 따라 이슈 대처 예정

---

## [기능개선-HashChain 2차]
- 주 담당자: 박세형 선임
- 예상 시행 시기: 9월, 10월

### 1. (15%-설계중) 기능개선-HashChain ver2
- TLV 를 사용한 next-hash 적용으로 프로세스를 줄이고자 함
- DIFS 뿐만 아니라 여러 application 에서 활용 가능할 수 있도록 하기 위함
- Signature Value 에 신규 TLV 추가
  - 현재 방향성 검증 중
- [Signature](https://named-data.net/doc/NDN-packet-spec/current/signature.html)

```
+------ Name ------+
| [Name]           |
+---- MetaInfo ----+
| [ContentType]    |
| [FreshnessPriod] |
| [FinalBlockId]   |
+---- Content -----+
| [Content]        |
+--- Signature ----+
| [SignatureInfo]  | -> SignatureType (add NEW TYPE X 2) / KeyLocator
| [SignatureValue] | -> add NEW TLV
+------------------+
```

|value|reference|description|
|:---:|:---|:---|
|0|[DigestSha256](https://named-data.net/doc/NDN-packet-spec/current/signature.html#digestsha256)||
|1|[SignatureSha256WithRsa](https://named-data.net/doc/NDN-packet-spec/current/signature.html#signaturesha256withrsa)||
|3|[SignatureSha256WithEcdsa](https://named-data.net/doc/NDN-packet-spec/current/signature.html#signaturesha256withecdsa)||
|4|[SignatureHmacWithSha256](https://named-data.net/doc/NDN-packet-spec/current/signature.html#signaturehmacwithsha256)||
|2, 5~200||Reserved for future assignments|
|>200||Unassigned|
||SignatureHCwithEcdsa|First packet of HashChain|
||SignatureHCwithSha256|non first packet of HashChain|
